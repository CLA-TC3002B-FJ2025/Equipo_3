# Título del Artículo

## Autores
Giuliana Herrera López, A01562646
Maria Ramirez, A01562798
Salvador Alejandro Robles Hernández, A01562588

## 1. Introducción

En el ámbito del desarrollo de software, existen productos de carácter internacional cuyas interfaces suelen estar escritas en inglés debido a su amplio uso en el mercado global. Sin embargo, al buscar mejorar la experiencia del usuario, muchas empresas optan por implementar traducciones en sus productos para adaptarse a un público más amplio y diverso.
No obstante, este enfoque presenta un desafío significativo: la necesidad de crear y traducir múltiples plantillas para cada idioma en el que se desee ofrecer el producto. Este proceso incrementa notablemente la complejidad del desarrollo del proyecto, tanto en términos técnicos como organizativos.
Uno de los principales desafíos que existen en los software de venta internacional son las traducciones de las interfaces. Actualmente, el 50% del contenido en internet está en inglés (Statista, n.d.); sin embargo, solo el 20% de la población mundial habla este idioma, lo que puede representar una barrera para el acceso a la información para quienes no lo dominan, como también para empresas que ofrezcan sus servicios a otros países, esto puede ser una desventaja al solo cubrir los lenguajes más “comunes”.  Sin embargo,  también se encuentran traducciones automáticas en navegadores, pero en muchos de los casos estos navegadores no soportan todas las lenguas o tienden a tener errores semánticos dentro de las traducciones.  Adicionalmente, la ambigüedad intrínseca de los lenguajes, que son las frases o palabras con múltiples significados, requieren un contexto semántico de las palabras y de donde se encuentran. 
De acuerdo a la revisión a la investigación sobre la traducción automática el uso de la IA ha evolucionado significativamente en la última década abriendo nuevas posibilidades para la traducción, aunque persisten desafíos claves. Estudios recientes destacan que, a pesar del avance de los modelos basados en redes neuronales (RNN) y transformadores (Vaswani et al., 2017), la calidad de las traducciones sigue siendo inconsistente en idiomas con recursos limitados. Este problema se agrava en contextos técnicos, donde la ambigüedad léxica y la falta de datos de entrenamiento especializados generan errores semánticos críticos (Hutchins, 2020).
Ante la problemática descrita, se propone la investigación sobre el empleo de Large Language Models (LLMs) como posible solución para optimizar la calidad de las traducciones en sitios web.Así mismo estos modelos cuentan con la capacidad para analizar y procesar contextos complejos y adaptarse a las variaciones lingüísticas según el contexto en el que se encuentre, sin embargo pueden tener también alucinaciones por lo cual es de suma importancia el prompt que se genere para el modelo a utilizar y con esto determinar una evaluación es decir un valor de precisión al momento de generar las traducciones (Lin, 2024).


## Referencias
  Capellini, R., Atienza, F., & Sconfield, M. (2024). Knowledge Accuracy and Reducing Hallucinations in LLMs via Dynamic Domain Knowledge Injection. https://doi.org/10.21203/rs.3.rs-4540506/v1
  ‌Zhang, R., Zhao, W., & Eger, S. (2024). How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs. ArXiv.org. https://arxiv.org/abs/2410.18697
‌	Lin, Z. (2024). How to write effective prompts for large language models. Nature Human Behaviour, 8(4), 611–615. https://doi.org/10.1038/s41562-024-01847-2
‌Chen, Y., Arkin, J., Hao, Y., Zhang, Y., Roy, N., & Fan, C. (2024). PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling. ArXiv.org. https://arxiv.org/abs/2402.08702
  Matviienko, L., Khomenko, L., Denysovets, I., Horodenska, K., Nikolashyna, T., & Pavlova, I. (2024). Comparative Analysis of Online Translators in the Machine Translation System. Romanian Journal for Multidimensional Education / Revista Românească Pentru Educaţie Multidimensională, 16(3), 101–118. https://doi.org/10.18662/rrem/16.3/885
  Hu, Y., Chen, C., Yang, C. H., Li, R., Zhang, D., Chen, Z., & Chng, E. S. (2024, 10 febrero). GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators. arXiv.org. https://arxiv.org/abs/2402.06894
  Naveed, H., Khan, A. U., Qiu, S., Saqib, M., Anwar, S., Usman, M., Akhtar, N.,
Barnes, N., & Mian, A. (2023). A Comprehensive Overview of Large Language
Models. ArXiv.org. https://arxiv.org/abs/2307.06435
  ‌Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). Attention is all you need. arXiv:1706.03762. https://doi.org/10.48550/arXiv.1706.03762
  Huan, X., & Zhou, H. (2024). Integrating Advanced Language Models and Vector Database for Enhanced AI Query Retrieval in Web Development. International Journal of Advanced Computer Science and Applications, 15(6). https://doi.org/10.14569/ijacsa.2024.0150601
  Inan, H., Upasani, K., Chi, J., Rungta, R., Iyer, K., Mao, Y., Tontchev, M., Hu, Q., Fuller, B., Testuggine, D., & Khabsa, M. (2023). Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations. https://arxiv.org/pdf/2312.06674

